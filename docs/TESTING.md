# MPU-6050 Kernel Driver - Testing Guide

## Table of Contents

- [Testing Overview](#testing-overview)
- [Unit Testing Framework](#unit-testing-framework)
- [End-to-End Testing](#end-to-end-testing)
- [Mock Framework Usage](#mock-framework-usage)
- [Coverage Reporting](#coverage-reporting)
- [CI/CD Integration](#cicd-integration)
- [Hardware-in-the-Loop Testing](#hardware-in-the-loop-testing)
- [Performance Testing](#performance-testing)
- [Security Testing](#security-testing)
- [Test Data and Scenarios](#test-data-and-scenarios)

## Testing Overview

The MPU-6050 kernel driver testing strategy employs a multi-layered approach to ensure reliability, performance, and security:

```
┌─────────────────────────────────────────────────────────────┐
│                    Testing Pyramid                         │
├─────────────────────────────────────────────────────────────┤
│                 E2E & Integration Tests                     │
│              ┌─────────────────────────────┐              │
│              │  Hardware-in-the-Loop       │              │
│              │  System Integration         │              │
│              └─────────────────────────────┘              │
├─────────────────────────────────────────────────────────────┤
│                    Component Tests                          │
│         ┌─────────────────────────────────────────┐       │
│         │  I2C Layer Tests                        │       │
│         │  Sysfs Interface Tests                  │       │
│         │  Character Device Tests                 │       │
│         │  Power Management Tests                 │       │
│         └─────────────────────────────────────────┘       │
├─────────────────────────────────────────────────────────────┤
│                     Unit Tests                              │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  Function-level Tests                                   │ │
│  │  Data Structure Tests                                   │ │
│  │  Error Handling Tests                                   │ │
│  │  Edge Case Tests                                        │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

### Testing Metrics

| Test Type | Target Coverage | Execution Time | Environment |
|-----------|----------------|----------------|-------------|
| Unit Tests | 95% | < 30 seconds | Mock/Simulated |
| Component Tests | 85% | < 2 minutes | Mock + Real I2C |
| Integration Tests | 75% | < 5 minutes | Real Hardware |
| E2E Tests | 60% | < 10 minutes | Complete System |

## Unit Testing Framework

### CUnit Framework Setup

The driver uses CUnit as the primary unit testing framework with custom kernel module testing extensions.

#### Test Structure

```c
/* tests/unit/test_mpu6050_core.c */
#include <CUnit/CUnit.h>
#include <CUnit/Basic.h>
#include "mpu6050_test_framework.h"
#include "mpu6050_mocks.h"

/* Test Suite Setup */
static int init_core_test_suite(void) {
    mock_i2c_reset();
    mock_kernel_reset();
    return 0;
}

static int clean_core_test_suite(void) {
    mock_cleanup();
    return 0;
}

/* Individual Test Cases */
static void test_mpu6050_device_probe(void) {
    struct i2c_client *mock_client;
    struct mpu6050_data *data;
    int ret;
    
    /* Setup mock I2C client */
    mock_client = mock_i2c_client_create(MPU6050_I2C_ADDR_LOW);
    mock_i2c_set_response(MPU6050_REG_WHO_AM_I, MPU6050_WHO_AM_I_VAL);
    
    /* Test probe function */
    ret = mpu6050_probe(mock_client, &mpu6050_i2c_id[0]);
    
    /* Assertions */
    CU_ASSERT_EQUAL(ret, 0);
    data = i2c_get_clientdata(mock_client);
    CU_ASSERT_PTR_NOT_NULL(data);
    CU_ASSERT_EQUAL(data->client, mock_client);
    
    /* Cleanup */
    mpu6050_remove(mock_client);
    mock_i2c_client_destroy(mock_client);
}

static void test_mpu6050_register_access(void) {
    struct mpu6050_data *data = create_mock_device();
    u8 value;
    int ret;
    
    /* Test register write */
    mock_i2c_set_write_expectation(MPU6050_REG_PWR_MGMT_1, 0x00);
    ret = mpu6050_i2c_write_reg(data, MPU6050_REG_PWR_MGMT_1, 0x00);
    CU_ASSERT_EQUAL(ret, 0);
    
    /* Test register read */
    mock_i2c_set_response(MPU6050_REG_PWR_MGMT_1, 0x00);
    ret = mpu6050_i2c_read_reg(data, MPU6050_REG_PWR_MGMT_1, &value);
    CU_ASSERT_EQUAL(ret, 0);
    CU_ASSERT_EQUAL(value, 0x00);
    
    destroy_mock_device(data);
}

static void test_mpu6050_sensor_data_conversion(void) {
    struct mpu6050_raw_data raw = {\n        .accel_x = 1000, .accel_y = 2000, .accel_z = 3000,\n        .gyro_x = 100, .gyro_y = 200, .gyro_z = 300,\n        .temp = 512\n    };\n    struct mpu6050_scaled_data scaled;\n    \n    /* Test data scaling with ±2g, ±250°/s ranges */\n    mpu6050_scale_sensor_data(&raw, &scaled, MPU6050_ACCEL_FS_2G, MPU6050_GYRO_FS_250);\n    \n    /* Verify accelerometer scaling (16384 LSB/g for ±2g range) */\n    CU_ASSERT_EQUAL(scaled.accel_x, (1000 * 1000) / 16384);  /* mg */\n    CU_ASSERT_EQUAL(scaled.accel_y, (2000 * 1000) / 16384);\n    CU_ASSERT_EQUAL(scaled.accel_z, (3000 * 1000) / 16384);\n    \n    /* Verify gyroscope scaling (131 LSB/°/s for ±250°/s range) */\n    CU_ASSERT_EQUAL(scaled.gyro_x, (100 * 1000) / 131);      /* mdps */\n    CU_ASSERT_EQUAL(scaled.gyro_y, (200 * 1000) / 131);\n    CU_ASSERT_EQUAL(scaled.gyro_z, (300 * 1000) / 131);\n}\n\nstatic void test_mpu6050_error_handling(void) {\n    struct mpu6050_data *data = create_mock_device();\n    u8 value;\n    int ret;\n    \n    /* Test I2C communication failure */\n    mock_i2c_set_error(-EIO);\n    ret = mpu6050_i2c_read_reg(data, MPU6050_REG_WHO_AM_I, &value);\n    CU_ASSERT_EQUAL(ret, -EIO);\n    CU_ASSERT_EQUAL(data->error_count, 1);\n    \n    /* Test invalid device ID */\n    mock_i2c_set_response(MPU6050_REG_WHO_AM_I, 0xFF);\n    ret = mpu6050_check_device_identity(data);\n    CU_ASSERT_EQUAL(ret, -ENODEV);\n    \n    destroy_mock_device(data);\n}\n\n/* Test Suite Registration */\nint register_core_test_suite(void) {\n    CU_pSuite pSuite = CU_add_suite(\"MPU6050_Core_Tests\", \n                                   init_core_test_suite, \n                                   clean_core_test_suite);\n    if (!pSuite) return CU_get_error();\n    \n    if (!CU_add_test(pSuite, \"Device Probe\", test_mpu6050_device_probe) ||\n        !CU_add_test(pSuite, \"Register Access\", test_mpu6050_register_access) ||\n        !CU_add_test(pSuite, \"Data Conversion\", test_mpu6050_sensor_data_conversion) ||\n        !CU_add_test(pSuite, \"Error Handling\", test_mpu6050_error_handling)) {\n        return CU_get_error();\n    }\n    \n    return 0;\n}\n```\n\n### Running Unit Tests\n\n```bash\n# Build and run all unit tests\nmake test\n\n# Run specific test suite\n./build/tests/test_mpu6050_core\n\n# Run with verbose output\n./build/tests/test_mpu6050_core --verbose\n\n# Run with memory checking (valgrind)\nmake test-valgrind\n```\n\n### Test Configuration\n\n```cmake\n# tests/CMakeLists.txt\ncmake_minimum_required(VERSION 3.10)\nproject(MPU6050Tests C)\n\n# Find required packages\nfind_package(PkgConfig REQUIRED)\npkg_check_modules(CUNIT REQUIRED cunit)\n\n# Test configuration\nset(CMAKE_C_STANDARD 99)\nset(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wall -Wextra -g\")\n\n# Coverage flags\nif(ENABLE_COVERAGE)\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} --coverage\")\n    set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} --coverage\")\nendif()\n\n# Include directories\ninclude_directories(${CMAKE_SOURCE_DIR}/../include)\ninclude_directories(${CMAKE_SOURCE_DIR}/mocks)\ninclude_directories(${CUNIT_INCLUDE_DIRS})\n\n# Test executables\nadd_executable(test_mpu6050_core \n    unit/test_mpu6050_core.c\n    mocks/mock_i2c.c\n    mocks/mock_kernel.c\n    framework/test_framework.c\n)\n\nadd_executable(test_mpu6050_sysfs\n    unit/test_mpu6050_sysfs.c\n    mocks/mock_sysfs.c\n    mocks/mock_kernel.c\n    framework/test_framework.c\n)\n\n# Link libraries\ntarget_link_libraries(test_mpu6050_core ${CUNIT_LIBRARIES})\ntarget_link_libraries(test_mpu6050_sysfs ${CUNIT_LIBRARIES})\n\n# Test discovery\nenable_testing()\nadd_test(NAME CoreTests COMMAND test_mpu6050_core)\nadd_test(NAME SysfsTests COMMAND test_mpu6050_sysfs)\n```\n\n## End-to-End Testing\n\n### E2E Test Framework\n\n```bash\n#!/bin/bash\n# tests/e2e/test_complete_workflow.sh\n\nset -e\n\nTEST_DIR=\"$(dirname \"$0\")\"\nPROJECT_ROOT=\"$(cd \"${TEST_DIR}/../..\" && pwd)\"\nMODULE_NAME=\"mpu6050\"\n\n# Test configuration\nTEST_DEVICE_ADDR=\"0x68\"\nTEST_I2C_BUS=\"1\"\nTEST_DURATION=\"60\"  # seconds\n\nsource \"${TEST_DIR}/../framework/e2e_framework.sh\"\n\n# E2E Test: Complete Driver Lifecycle\ntest_driver_lifecycle() {\n    log_info \"Testing complete driver lifecycle\"\n    \n    # Step 1: Load module\n    load_module \"${PROJECT_ROOT}/build/${MODULE_NAME}.ko\"\n    assert_module_loaded \"${MODULE_NAME}\"\n    \n    # Step 2: Verify device detection\n    sleep 2\n    assert_file_exists \"/sys/class/mpu6050/mpu6050\"\n    assert_file_exists \"/dev/mpu6050\"\n    \n    # Step 3: Test sysfs interface\n    test_sysfs_interface\n    \n    # Step 4: Test character device\n    test_character_device\n    \n    # Step 5: Test configuration changes\n    test_configuration\n    \n    # Step 6: Stress test\n    test_stress_scenarios\n    \n    # Step 7: Unload module\n    unload_module \"${MODULE_NAME}\"\n    assert_module_not_loaded \"${MODULE_NAME}\"\n    \n    log_success \"Driver lifecycle test completed\"\n}\n\ntest_sysfs_interface() {\n    log_info \"Testing sysfs interface\"\n    \n    local sysfs_path=\"/sys/class/mpu6050/mpu6050\"\n    \n    # Test basic data reading\n    for attr in accel_data gyro_data temp_data; do\n        assert_file_readable \"${sysfs_path}/${attr}\"\n        local value=$(cat \"${sysfs_path}/${attr}\")\n        assert_not_empty \"${value}\" \"${attr} should return data\"\n    done\n    \n    # Test scaled data reading\n    for attr in accel_scale gyro_scale temp_celsius; do\n        assert_file_readable \"${sysfs_path}/${attr}\"\n        local value=$(cat \"${sysfs_path}/${attr}\")\n        assert_not_empty \"${value}\" \"${attr} should return scaled data\"\n    done\n    \n    # Test configuration attributes\n    for range in 0 1 2 3; do\n        echo \"${range}\" > \"${sysfs_path}/accel_range\"\n        local actual=$(cat \"${sysfs_path}/accel_range\")\n        assert_equal \"${range}\" \"${actual}\" \"Accelerometer range setting\"\n    done\n    \n    # Test power management\n    echo \"0\" > \"${sysfs_path}/power_state\"  # Sleep\n    local state=$(cat \"${sysfs_path}/power_state\")\n    assert_equal \"0\" \"${state}\" \"Sleep state\"\n    \n    echo \"1\" > \"${sysfs_path}/power_state\"  # Wake\n    local state=$(cat \"${sysfs_path}/power_state\")\n    assert_equal \"1\" \"${state}\" \"Wake state\"\n    \n    log_success \"Sysfs interface test passed\"\n}\n\ntest_character_device() {\n    log_info \"Testing character device interface\"\n    \n    # Compile test program\n    gcc -o \"${TEST_DIR}/chardev_test\" \\\n        \"${TEST_DIR}/chardev_test.c\" \\\n        -I\"${PROJECT_ROOT}/include\"\n    \n    # Run character device tests\n    \"${TEST_DIR}/chardev_test\" /dev/mpu6050\n    \n    log_success \"Character device test passed\"\n}\n\ntest_configuration() {\n    log_info \"Testing sensor configuration\"\n    \n    # Test different sampling rates\n    for rate_div in 7 15 31 63; do\n        echo \"${rate_div}\" > /sys/class/mpu6050/mpu6050/sample_rate\n        sleep 1\n        local actual=$(cat /sys/class/mpu6050/mpu6050/sample_rate)\n        assert_equal \"${rate_div}\" \"${actual}\" \"Sample rate ${rate_div}\"\n    done\n    \n    # Test self-test\n    local result=$(cat /sys/class/mpu6050/mpu6050/self_test)\n    assert_not_equal \"0\" \"${result}\" \"Self-test should return non-zero\"\n    \n    log_success \"Configuration test passed\"\n}\n\ntest_stress_scenarios() {\n    log_info \"Running stress tests for ${TEST_DURATION} seconds\"\n    \n    # Concurrent access test\n    bash \"${TEST_DIR}/stress/concurrent_access.sh\" \"${TEST_DURATION}\" &\n    local stress_pid=$!\n    \n    # Rapid configuration changes\n    bash \"${TEST_DIR}/stress/rapid_config.sh\" \"${TEST_DURATION}\" &\n    local config_pid=$!\n    \n    # High-frequency reading\n    bash \"${TEST_DIR}/stress/high_frequency.sh\" \"${TEST_DURATION}\" &\n    local freq_pid=$!\n    \n    # Wait for all stress tests\n    wait ${stress_pid} && log_info \"Concurrent access stress test passed\"\n    wait ${config_pid} && log_info \"Configuration stress test passed\"\n    wait ${freq_pid} && log_info \"High frequency stress test passed\"\n    \n    log_success \"Stress tests completed\"\n}\n\n# Character device test program\ncat > \"${TEST_DIR}/chardev_test.c\" << 'EOF'\n#include <stdio.h>\n#include <stdlib.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <sys/ioctl.h>\n#include <errno.h>\n#include \"mpu6050.h\"\n\nint main(int argc, char *argv[]) {\n    if (argc != 2) {\n        fprintf(stderr, \"Usage: %s <device>\\n\", argv[0]);\n        return 1;\n    }\n    \n    int fd = open(argv[1], O_RDWR);\n    if (fd < 0) {\n        perror(\"open\");\n        return 1;\n    }\n    \n    /* Test IOCTL commands */\n    struct mpu6050_raw_data raw_data;\n    if (ioctl(fd, MPU6050_IOC_READ_RAW, &raw_data) == 0) {\n        printf(\"Raw data: accel(%d,%d,%d) gyro(%d,%d,%d) temp(%d)\\n\",\n               raw_data.accel_x, raw_data.accel_y, raw_data.accel_z,\n               raw_data.gyro_x, raw_data.gyro_y, raw_data.gyro_z,\n               raw_data.temp);\n    } else {\n        perror(\"ioctl READ raw\");\n        close(fd);\n        return 1;\n    }\n    \n    struct mpu6050_scaled_data scaled_data;\n    if (ioctl(fd, MPU6050_IOC_READ_SCALED, &scaled_data) == 0) {\n        printf(\"Scaled data: accel(%d,%d,%d)mg gyro(%d,%d,%d)mdps temp(%d)\\n\",\n               scaled_data.accel_x, scaled_data.accel_y, scaled_data.accel_z,\n               scaled_data.gyro_x, scaled_data.gyro_y, scaled_data.gyro_z,\n               scaled_data.temp);\n    } else {\n        perror(\"ioctl read scaled\");\n        close(fd);\n        return 1;\n    }\n    \n    /* Test device reset */\n    if (ioctl(fd, MPU6050_IOC_RESET) != 0) {\n        perror(\"ioctl reset\");\n        close(fd);\n        return 1;\n    }\n    \n    printf(\"Character device tests passed\\n\");\n    close(fd);\n    return 0;\n}\nEOF\n\n# Run the complete test suite\nmain() {\n    log_info \"Starting MPU-6050 E2E test suite\"\n    \n    check_prerequisites\n    setup_test_environment\n    \n    test_driver_lifecycle\n    \n    cleanup_test_environment\n    \n    log_success \"All E2E tests passed!\"\n}\n\nmain \"$@\"\n```\n\n### Running E2E Tests\n\n```bash\n# Run complete E2E test suite\n./tests/e2e/test_complete_workflow.sh\n\n# Run specific E2E test\n./tests/e2e/test_sysfs_only.sh\n\n# Run E2E tests with hardware simulation\nHW_SIMULATE=1 ./tests/e2e/test_complete_workflow.sh\n```\n\n## Mock Framework Usage\n\n### I2C Mock Implementation\n\n```c\n/* tests/mocks/mock_i2c.c */\n#include \"mock_i2c.h\"\n#include <stdlib.h>\n#include <string.h>\n\n/* Mock I2C state */\nstatic struct {\n    u8 registers[256];\n    int error_code;\n    bool error_enabled;\n    struct {\n        u8 reg;\n        u8 value;\n        bool valid;\n    } expectations[32];\n    int expectation_count;\n} mock_i2c_state;\n\nvoid mock_i2c_reset(void) {\n    memset(&mock_i2c_state, 0, sizeof(mock_i2c_state));\n    \n    /* Set default register values */\n    mock_i2c_state.registers[MPU6050_REG_WHO_AM_I] = MPU6050_WHO_AM_I_VAL;\n    mock_i2c_state.registers[MPU6050_REG_PWR_MGMT_1] = MPU6050_PWR1_SLEEP;\n}\n\nvoid mock_i2c_set_response(u8 reg, u8 value) {\n    mock_i2c_state.registers[reg] = value;\n}\n\nvoid mock_i2c_set_error(int error_code) {\n    mock_i2c_state.error_code = error_code;\n    mock_i2c_state.error_enabled = true;\n}\n\nvoid mock_i2c_set_write_expectation(u8 reg, u8 value) {\n    if (mock_i2c_state.expectation_count < 32) {\n        int idx = mock_i2c_state.expectation_count++;\n        mock_i2c_state.expectations[idx].reg = reg;\n        mock_i2c_state.expectations[idx].value = value;\n        mock_i2c_state.expectations[idx].valid = true;\n    }\n}\n\n/* Mock I2C functions */\nint mock_i2c_smbus_read_byte_data(const struct i2c_client *client, u8 reg) {\n    if (mock_i2c_state.error_enabled) {\n        mock_i2c_state.error_enabled = false;\n        return mock_i2c_state.error_code;\n    }\n    \n    return mock_i2c_state.registers[reg];\n}\n\nint mock_i2c_smbus_write_byte_data(const struct i2c_client *client, u8 reg, u8 value) {\n    if (mock_i2c_state.error_enabled) {\n        mock_i2c_state.error_enabled = false;\n        return mock_i2c_state.error_code;\n    }\n    \n    /* Check expectations */\n    for (int i = 0; i < mock_i2c_state.expectation_count; i++) {\n        if (mock_i2c_state.expectations[i].valid &&\n            mock_i2c_state.expectations[i].reg == reg) {\n            if (mock_i2c_state.expectations[i].value != value) {\n                return -EINVAL;  /* Expectation mismatch */\n            }\n            mock_i2c_state.expectations[i].valid = false;\n            break;\n        }\n    }\n    \n    mock_i2c_state.registers[reg] = value;\n    return 0;\n}\n\nstruct i2c_client *mock_i2c_client_create(u8 addr) {\n    struct i2c_client *client = calloc(1, sizeof(*client));\n    if (client) {\n        client->addr = addr;\n        /* Initialize other necessary fields */\n    }\n    return client;\n}\n\nvoid mock_i2c_client_destroy(struct i2c_client *client) {\n    free(client);\n}\n```\n\n### Kernel Mock Implementation\n\n```c\n/* tests/mocks/mock_kernel.c */\n#include \"mock_kernel.h\"\n\n/* Mock kernel memory allocation */\nvoid *mock_devm_kzalloc(struct device *dev, size_t size, gfp_t gfp) {\n    return calloc(1, size);\n}\n\nvoid mock_devm_kfree(struct device *dev, void *ptr) {\n    free(ptr);\n}\n\n/* Mock mutex operations */\nvoid mock_mutex_init(struct mutex *lock) {\n    /* Initialize mutex simulation */\n    lock->locked = false;\n}\n\nvoid mock_mutex_lock(struct mutex *lock) {\n    lock->locked = true;\n}\n\nvoid mock_mutex_unlock(struct mutex *lock) {\n    lock->locked = false;\n}\n\n/* Mock device operations */\nvoid mock_dev_info(const struct device *dev, const char *fmt, ...) {\n    va_list args;\n    va_start(args, fmt);\n    printf(\"[INFO] \");\n    vprintf(fmt, args);\n    va_end(args);\n}\n\nvoid mock_dev_err(const struct device *dev, const char *fmt, ...) {\n    va_list args;\n    va_start(args, fmt);\n    printf(\"[ERROR] \");\n    vprintf(fmt, args);\n    va_end(args);\n}\n```\n\n## Coverage Reporting\n\n### Generating Coverage Reports\n\n```bash\n# Build with coverage instrumentation\nmake clean\nmake COVERAGE=1\n\n# Run all tests\nmake test\n\n# Generate coverage report\nmake coverage\n\n# View HTML coverage report\nopen coverage/index.html\n```\n\n### Coverage Configuration\n\n```makefile\n# Makefile coverage targets\nCOVERAGE_DIR ?= coverage\nLCOV_OPTS = --rc lcov_branch_coverage=1\n\ncoverage: test\n\t@echo \"Generating coverage report...\"\n\tlcov $(LCOV_OPTS) --capture --directory . --output-file $(COVERAGE_DIR)/coverage.info\n\tlcov $(LCOV_OPTS) --remove $(COVERAGE_DIR)/coverage.info '/usr/*' '*/tests/*' --output-file $(COVERAGE_DIR)/coverage.info\n\tgenhtml $(LCOV_OPTS) $(COVERAGE_DIR)/coverage.info --output-directory $(COVERAGE_DIR)\n\t@echo \"Coverage report generated in $(COVERAGE_DIR)/index.html\"\n\ncoverage-summary:\n\tlcov $(LCOV_OPTS) --summary $(COVERAGE_DIR)/coverage.info\n```\n\n### Coverage Targets\n\n| Component | Target | Current |\n|-----------|--------|---------|\n| Core Driver | 95% | 92% |\n| I2C Layer | 90% | 88% |\n| Sysfs Interface | 85% | 82% |\n| Character Device | 85% | 79% |\n| Error Handling | 80% | 75% |\n| Overall | 85% | 83% |\n\n## CI/CD Integration\n\n### GitHub Actions Workflow\n\n```yaml\n# .github/workflows/ci.yml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - name: Install dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y clang-format cppcheck\n    - name: Run linting\n      run: ./scripts/lint.sh --all\n\n  unit-tests:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        kernel: [\"5.4\", \"5.15\", \"6.1\"]\n    steps:\n    - uses: actions/checkout@v3\n    - name: Setup kernel headers\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y linux-headers-$(uname -r) build-essential\n    - name: Install test dependencies\n      run: |\n        sudo apt-get install -y libcunit1-dev lcov\n    - name: Run unit tests\n      run: |\n        make clean\n        make COVERAGE=1\n        make test\n    - name: Generate coverage\n      run: make coverage\n    - name: Upload coverage to Codecov\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage/coverage.info\n\n  integration-tests:\n    runs-on: ubuntu-latest\n    needs: unit-tests\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build kernel module\n      run: make modules\n    - name: Run integration tests\n      run: |\n        sudo modprobe i2c-dev\n        ./tests/integration/run_all.sh\n\n  security-scan:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - name: Run security analysis\n      run: ./scripts/lint.sh --security-scan\n    - name: Upload SARIF results\n      uses: github/codeql-action/upload-sarif@v2\n      if: always()\n      with:\n        sarif_file: lint-results/security_scan.sarif\n```\n\n### Jenkins Pipeline\n\n```groovy\n// Jenkinsfile\npipeline {\n    agent any\n    \n    environment {\n        COVERAGE_THRESHOLD = '85'\n    }\n    \n    stages {\n        stage('Checkout') {\n            steps {\n                git branch: 'main', url: 'https://github.com/murr2k/linux-exam.git'\n            }\n        }\n        \n        stage('Build') {\n            parallel {\n                stage('Kernel Module') {\n                    steps {\n                        sh 'make clean && make modules'\n                    }\n                }\n                stage('Test Suite') {\n                    steps {\n                        sh 'make COVERAGE=1'\n                    }\n                }\n            }\n        }\n        \n        stage('Test') {\n            parallel {\n                stage('Unit Tests') {\n                    steps {\n                        sh 'make test'\n                    }\n                    post {\n                        always {\n                            publishTestResults testResultsPattern: 'test-results/unit/*.xml'\n                        }\n                    }\n                }\n                stage('Integration Tests') {\n                    steps {\n                        sh 'sudo ./tests/integration/run_all.sh'\n                    }\n                    post {\n                        always {\n                            publishTestResults testResultsPattern: 'test-results/integration/*.xml'\n                        }\n                    }\n                }\n                stage('Lint & Security') {\n                    steps {\n                        sh './scripts/lint.sh --all'\n                    }\n                    post {\n                        always {\n                            publishCheckStyleResults pattern: 'lint-results/*.xml'\n                        }\n                    }\n                }\n            }\n        }\n        \n        stage('Coverage') {\n            steps {\n                sh 'make coverage'\n            }\n            post {\n                success {\n                    publishCoverageResults(\n                        adapters: [lcovAdapter('coverage/coverage.info')],\n                        sourceFileResolver: sourceFiles('STORE_LAST_BUILD')\n                    )\n                }\n            }\n        }\n        \n        stage('Deploy') {\n            when { branch 'main' }\n            steps {\n                script {\n                    if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {\n                        sh 'make package'\n                        archiveArtifacts artifacts: 'dist/*.tar.gz', fingerprint: true\n                    }\n                }\n            }\n        }\n    }\n    \n    post {\n        always {\n            cleanWs()\n        }\n        failure {\n            emailext(\n                subject: \"Build Failed: ${env.JOB_NAME} - ${env.BUILD_NUMBER}\",\n                body: \"Build failed. Check console output at ${env.BUILD_URL}\",\n                to: \"murr2k@gmail.com\"\n            )\n        }\n    }\n}\n```\n\n## Hardware-in-the-Loop Testing\n\n### Physical Test Setup\n\n```\n┌─────────────────┐    I2C     ┌─────────────────┐\n│   Test Host     │◄──────────►│   MPU-6050      │\n│   (Raspberry Pi)│            │   Sensor Board  │\n└─────────────────┘            └─────────────────┘\n        │                              │\n        │          Power Supply        │\n        └──────────────────────────────┘\n```\n\n### Automated Hardware Tests\n\n```bash\n#!/bin/bash\n# tests/hardware/automated_hw_test.sh\n\nHW_TEST_CONFIG=\"/etc/mpu6050-test.conf\"\nTEST_RESULTS_DIR=\"test-results/hardware\"\n\n# Load hardware test configuration\nsource \"${HW_TEST_CONFIG}\"\n\n# Test physical sensor responses\ntest_sensor_movement() {\n    log_info \"Testing sensor movement detection\"\n    \n    # Baseline readings\n    local baseline_x=$(cat /sys/class/mpu6050/mpu6050/accel_scale | cut -d' ' -f1)\n    local baseline_y=$(cat /sys/class/mpu6050/mpu6050/accel_scale | cut -d' ' -f2)\n    local baseline_z=$(cat /sys/class/mpu6050/mpu6050/accel_scale | cut -d' ' -f3)\n    \n    log_info \"Please tilt sensor 45 degrees and press Enter\"\n    read -r\n    \n    # Movement readings\n    local moved_x=$(cat /sys/class/mpu6050/mpu6050/accel_scale | cut -d' ' -f1)\n    local moved_y=$(cat /sys/class/mpu6050/mpu6050/accel_scale | cut -d' ' -f2)\n    local moved_z=$(cat /sys/class/mpu6050/mpu6050/accel_scale | cut -d' ' -f3)\n    \n    # Calculate differences\n    local diff_x=$((moved_x - baseline_x))\n    local diff_y=$((moved_y - baseline_y))\n    local diff_z=$((moved_z - baseline_z))\n    \n    # Verify significant change (>500mg)\n    if [ ${diff_x#-} -gt 500 ] || [ ${diff_y#-} -gt 500 ] || [ ${diff_z#-} -gt 500 ]; then\n        log_success \"Movement detected: (${diff_x}, ${diff_y}, ${diff_z}) mg\"\n    else\n        log_error \"No significant movement detected\"\n        return 1\n    fi\n}\n\ntest_temperature_sensor() {\n    log_info \"Testing temperature sensor\"\n    \n    local temp=$(cat /sys/class/mpu6050/mpu6050/temp_celsius)\n    \n    # Reasonable temperature range (0-50°C for typical environments)\n    if [ \"${temp}\" -gt 0 ] && [ \"${temp}\" -lt 5000 ]; then  # temp in centidegrees\n        log_success \"Temperature reading: $((temp / 100))°C\"\n    else\n        log_error \"Temperature out of range: ${temp}\"\n        return 1\n    fi\n}\n\n# Run hardware test suite\nrun_hardware_tests() {\n    mkdir -p \"${TEST_RESULTS_DIR}\"\n    \n    test_sensor_movement\n    test_temperature_sensor\n    \n    # Additional automated tests...\n}\n\nrun_hardware_tests\n```\n\n## Performance Testing\n\n### Throughput Testing\n\n```c\n/* tests/performance/throughput_test.c */\n#include <time.h>\n#include <sys/time.h>\n#include \"mpu6050.h\"\n\n#define TEST_DURATION_SEC 10\n#define MAX_SAMPLES 100000\n\nstruct perf_stats {\n    long samples;\n    double min_time;\n    double max_time;\n    double avg_time;\n    double total_time;\n};\n\nint performance_test_sysfs(struct perf_stats *stats) {\n    struct timeval start, end, sample_start, sample_end;\n    char buffer[256];\n    FILE *fp;\n    long samples = 0;\n    double sample_time, min_time = 1.0, max_time = 0.0, total_time = 0.0;\n    \n    gettimeofday(&start, NULL);\n    \n    while (samples < MAX_SAMPLES) {\n        gettimeofday(&sample_start, NULL);\n        \n        fp = fopen(\"/sys/class/mpu6050/mpu6050/accel_data\", \"r\");\n        if (!fp) break;\n        \n        if (!fgets(buffer, sizeof(buffer), fp)) {\n            fclose(fp);\n            break;\n        }\n        fclose(fp);\n        \n        gettimeofday(&sample_end, NULL);\n        \n        sample_time = (sample_end.tv_sec - sample_start.tv_sec) + \n                     (sample_end.tv_usec - sample_start.tv_usec) / 1000000.0;\n        \n        if (sample_time < min_time) min_time = sample_time;\n        if (sample_time > max_time) max_time = sample_time;\n        total_time += sample_time;\n        \n        samples++;\n        \n        gettimeofday(&end, NULL);\n        if (end.tv_sec - start.tv_sec >= TEST_DURATION_SEC) break;\n    }\n    \n    stats->samples = samples;\n    stats->min_time = min_time;\n    stats->max_time = max_time;\n    stats->avg_time = total_time / samples;\n    stats->total_time = total_time;\n    \n    return 0;\n}\n\nint main() {\n    struct perf_stats sysfs_stats, ioctl_stats;\n    \n    printf(\"MPU-6050 Performance Test\\n\");\n    printf(\"Test duration: %d seconds\\n\\n\", TEST_DURATION_SEC);\n    \n    /* Test sysfs performance */\n    printf(\"Testing sysfs interface...\\n\");\n    performance_test_sysfs(&sysfs_stats);\n    \n    printf(\"Sysfs Results:\\n\");\n    printf(\"  Samples: %ld\\n\", sysfs_stats.samples);\n    printf(\"  Throughput: %.1f samples/sec\\n\", sysfs_stats.samples / TEST_DURATION_SEC);\n    printf(\"  Min time: %.3f ms\\n\", sysfs_stats.min_time * 1000);\n    printf(\"  Max time: %.3f ms\\n\", sysfs_stats.max_time * 1000);\n    printf(\"  Avg time: %.3f ms\\n\\n\", sysfs_stats.avg_time * 1000);\n    \n    /* Test IOCTL performance */\n    printf(\"Testing IOCTL interface...\\n\");\n    performance_test_ioctl(&ioctl_stats);\n    \n    printf(\"IOCTL Results:\\n\");\n    printf(\"  Samples: %ld\\n\", ioctl_stats.samples);\n    printf(\"  Throughput: %.1f samples/sec\\n\", ioctl_stats.samples / TEST_DURATION_SEC);\n    printf(\"  Min time: %.3f ms\\n\", ioctl_stats.min_time * 1000);\n    printf(\"  Max time: %.3f ms\\n\", ioctl_stats.max_time * 1000);\n    printf(\"  Avg time: %.3f ms\\n\\n\", ioctl_stats.avg_time * 1000);\n    \n    return 0;\n}\n```\n\n### Memory Leak Testing\n\n```bash\n#!/bin/bash\n# tests/performance/memory_leak_test.sh\n\nTEST_ITERATIONS=1000\nMODULE_NAME=\"mpu6050\"\n\nlog_memory_usage() {\n    local iteration=$1\n    local mem_info\n    \n    # Get memory usage from /proc/meminfo\n    mem_info=$(grep -E \"MemFree|MemAvailable\" /proc/meminfo)\n    \n    echo \"Iteration ${iteration}: ${mem_info}\" >> memory_usage.log\n}\n\ntest_module_load_unload_leak() {\n    log_info \"Testing module load/unload memory leaks\"\n    \n    echo \"Iteration,MemFree,MemAvailable\" > memory_leak_test.csv\n    \n    for i in $(seq 1 ${TEST_ITERATIONS}); do\n        # Load module\n        sudo insmod build/${MODULE_NAME}.ko\n        sleep 0.1\n        \n        # Record memory usage\n        log_memory_usage ${i}\n        \n        # Unload module\n        sudo rmmod ${MODULE_NAME}\n        sleep 0.1\n        \n        if [ $((i % 100)) -eq 0 ]; then\n            log_info \"Completed ${i}/${TEST_ITERATIONS} iterations\"\n        fi\n    done\n    \n    # Analyze results\n    python3 analyze_memory_usage.py memory_leak_test.csv\n}\n\ntest_module_load_unload_leak\n```\n\nThis comprehensive testing guide provides a complete framework for ensuring the MPU-6050 kernel driver's reliability, performance, and security through automated testing at all levels.